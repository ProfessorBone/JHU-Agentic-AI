{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyS2Ovli5gq2"
   },
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "In this notebook, we will demonstrate the fundementals of using LangChain for prompt engineering. Specifically, we will do the following:\n",
    "\n",
    "- create a prompt from a template\n",
    "- create a LLM\n",
    "- create a chain\n",
    "- look at some specialized chains for few-shot prompting\n",
    "\n",
    "For this  exercise, we are going to focus on a classification task. Namely, the classification of the \"stance\" of a comment towards another comment. The base comment is given below:\n",
    "\n",
    "```python\n",
    "comment = \"The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\"\n",
    "```\n",
    "\n",
    "The replies to the comment that we will classify for their stance toward the comment as \"agree\", \"disagree\", and \"neutral\" are:\n",
    "\n",
    "```python\n",
    "replies = [\n",
    "    \"The newer ones fail to live up to the sophistry of the older movies from the 70's.\",\n",
    "    \"Frank Herbert wrote a lot of books.\",\n",
    "    \"I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\",\n",
    "    \"The quick red fox jumped over the lazy brown dog.\",\n",
    "    \"Yeah, this new movie is a real masterpiece, lol!!\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--I4xWYW5gq7"
   },
   "source": [
    "## Configure the environment\n",
    "\n",
    "I need your help with classifying the stance of replies to comments about a topic using LangChain and Langchain-Huggingface for running local models. First, I need the code to install the neccesary packages from a notebook envrionment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RowDP8ff5gq8",
    "outputId": "5acd83cf-93c8-47a9-e414-bb9d19245bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (0.4.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-huggingface) (0.3.76)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-huggingface) (0.22.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.27)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: requests in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.10)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/faheem/Documents/Greater Learning/Agentic AI/agentic_ai_env/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages for LangChain stance classification with local models\n",
    "\n",
    "%pip install langchain\n",
    "%pip install transformers\n",
    "%pip install langchain-huggingface\n",
    "%pip install torch\n",
    "%pip install accelerate\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prompt object\n",
    "I need your help with classifying the stance of comments using LangChain. First, I need you to give me the code to create a prompt object, called \"stance_prompt\" from LangChain around the following template: '''Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label. comment: {comment} reply: {reply} stance:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NU4fDbQB5gq_",
    "outputId": "dac58bc9-1e60-4d91-9866-ca7c1e850eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted prompt:\n",
      "Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label.\n",
      "comment: I think this policy is not effective.\n",
      "reply: I agree, it doesn't address the core issues.\n",
      "stance:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the template for stance classification\n",
    "template = '''Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:'''\n",
    "\n",
    "# Create the prompt object\n",
    "stance_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "# Example usage - Test the prompt formatting\n",
    "comment = \"I think this policy is not effective.\"\n",
    "reply = \"I agree, it doesn't address the core issues.\"\n",
    "\n",
    "# Format the prompt with actual values\n",
    "formatted_prompt = stance_prompt.format(comment=comment, reply=reply)\n",
    "print(\"Formatted prompt:\")\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSSsDeKQ5gq_"
   },
   "source": [
    "## Create an LLM object\n",
    "\n",
    "### Option 1: Using a small encoder-decoder model\n",
    "Now, I need you to create an LLM object using LangChain. In particular, I would like to use the text2text-generation model of \"declare-lab/flan-alpaca-gpt4-xl\" from HuggingFace and use the CPU. Make sure to import the langchain HuggingFace pipeline as \"from langchain_huggingface import HuggingFacePipeline\". Also, make sure when creating the pipeline to specify \"max_new_tokens = 500\", and make sure the pipeline only outputs the generated text and not text from the prompt.\n",
    "\n",
    "```python\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the model using Hugging Face pipeline\n",
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"declare-lab/flan-alpaca-gpt4-xl\",\n",
    "    device=0,  # Use GPU (-1 for CPU)\n",
    "    max_new_tokens = 500,\n",
    ")\n",
    "\n",
    "# Create the LangChain LLM using the HuggingFace pipeline\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Example usage with the prompt object from before\n",
    "prompt = '''Please classify the stance, or opinion, of the following reply to the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words.\n",
    "comment: I think the new policy will help improve efficiency.\n",
    "reply: I disagree, the policy doesn't address the real issues.\n",
    "stance:'''\n",
    "\n",
    "# Get the model's response\n",
    "response = llm(prompt)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "### Option 2: Using a small decoder-only model\n",
    "Now, I need you to create an LLM object using LangChain. In particular, I would like to use the text-generation model of \"tiiuae/Falcon3-1B-Instruct\" from HuggingFace and use the CPU. Make sure to import the langchain HuggingFace pipeline as \"from langchain_huggingface import HuggingFacePipeline\". Also, make sure when creating the pipeline to specify \"max_new_tokens = 500\", and make sure the pipeline only outputs the generated text and not the prompt.\n",
    "\n",
    "```python\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/Falcon3-3B-Instruct\",\n",
    "    device=0,  # Use GPU (-1 for CPU)\n",
    "    max_new_tokens = 500,\n",
    "    return_full_text=False\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "57503e437a0947068985d92302bb5a99",
      "090f0fb4b5b043df91280f4a05f2a110",
      "4dd918f565a446fa9b8e77b87a9a56fa",
      "f6ed95119f5242ae900c56c0b14dafbc",
      "af778a7c76aa4f8ea1c190394667d8e9",
      "9db64bbd996c4b1eb55346c051848225",
      "ac1dec2fcbd848578e9c87ca57040b30",
      "ed0ff2bb755f41ef9070e8ee0af0b7b3",
      "832e195a263048909254c5ccd87e8c62",
      "2079f966cb1348f29ce87ab007e79eaa"
     ]
    },
    "id": "GcJxbbQG5gq_",
    "outputId": "9d6c565e-a370-400f-a67b-aedb54172d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "MPS (Apple Silicon GPU): True\n",
      "CPU cores: Available\n",
      "Using device: MPS (Apple Silicon GPU)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0969efa98d7847918f3a03f665667ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the LLM...\n",
      "Input prompt:\n",
      "Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label.\n",
      "comment: I think the new policy will help improve efficiency.\n",
      "reply: I disagree, the policy doesn't address the real issues.\n",
      "stance:\n",
      "\n",
      "Model response:\n",
      " disagree\n",
      " disagree\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check available devices on your Mac\n",
    "print(\"Available devices:\")\n",
    "print(f\"MPS (Apple Silicon GPU): {torch.backends.mps.is_available()}\")\n",
    "print(f\"CPU cores: Available\")\n",
    "\n",
    "# Use MPS if available, fallback to CPU\n",
    "device = 0 if torch.backends.mps.is_available() else -1\n",
    "print(f\"Using device: {'MPS (Apple Silicon GPU)' if device == 0 else 'CPU'}\")\n",
    "\n",
    "# Create the Hugging Face pipeline\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"tiiuae/Falcon3-3B-Instruct\",\n",
    "    device=device,  # Will use MPS (Apple Silicon GPU) if available\n",
    "    max_new_tokens=500,\n",
    "    return_full_text=False  # Only return generated text, not the prompt\n",
    ")\n",
    "\n",
    "# Create the LangChain LLM using the HuggingFace pipeline\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# Test the LLM with a simple example\n",
    "test_prompt = '''Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label.\n",
    "comment: I think the new policy will help improve efficiency.\n",
    "reply: I disagree, the policy doesn't address the real issues.\n",
    "stance:'''\n",
    "\n",
    "# Get the model's response\n",
    "print(\"Testing the LLM...\")\n",
    "print(\"Input prompt:\")\n",
    "print(test_prompt)\n",
    "print(\"\\nModel response:\")\n",
    "response = llm.invoke(test_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h0G4UPb5grA"
   },
   "source": [
    "## Create a Chain\n",
    "\n",
    "Now, I would like the python code to create a LangChain Chain from the prompt template \"stance_prompt\" and the LLM \"llm\". Make sure to use the \"|\" syntax for defining the chain. and call the chain by the \"invoke\" method. Please name the chain \"stance_chain\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W18QHavF5grB",
    "outputId": "3e140af9-82f9-444c-f8ac-cbd99222c1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain created successfully!\n",
      "Chain components: first=PromptTemplate(input_variables=['comment', 'reply'], input_types={}, partial_variables={}, template='Please classify the stance, or opinion, of the following reply to the comment. Note that we want the stance of the reply to the comment, and not the stance of the reply to topic of the comment. Only give the stance as \"agree\", \"disagree\", or \"neutral\" and output no other words after outputing the label.\\ncomment: {comment}\\nreply: {reply}\\nstance:') middle=[] last=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x12fa881a0>, model_id='tiiuae/Falcon3-3B-Instruct')\n",
      "\n",
      "Testing the complete chain...\n",
      "==================================================\n",
      "Comment: The new delivery route optimization will save us fuel costs.\n",
      "Reply: I disagree, the system is too complicated and won't really help.\n",
      "==================================================\n",
      "Chain result:\n",
      "Stance:  disagree\n",
      "==================================================\n",
      "Chain result:\n",
      "Stance:  disagree\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the chain using the \"|\" (pipe) syntax\n",
    "stance_chain = stance_prompt | llm\n",
    "\n",
    "print(\"Chain created successfully!\")\n",
    "print(\"Chain components:\", stance_chain)\n",
    "print()\n",
    "\n",
    "# Example usage: Test the complete chain\n",
    "comment = \"The new delivery route optimization will save us fuel costs.\"\n",
    "reply = \"I disagree, the system is too complicated and won't really help.\"\n",
    "\n",
    "# Use invoke method with input as a dictionary\n",
    "print(\"Testing the complete chain...\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Comment: {comment}\")\n",
    "print(f\"Reply: {reply}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Invoke the chain with the input dictionary\n",
    "result = stance_chain.invoke({\n",
    "    \"comment\": comment, \n",
    "    \"reply\": reply\n",
    "})\n",
    "\n",
    "print(\"Chain result:\")\n",
    "print(f\"Stance: {result}\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgrinvs_5grC"
   },
   "source": [
    "Great. Now, I would like to code to run the previously defined \"stance_chain\" on a comment called \"test_comment\" across each entry in a list called \"test_replies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x9tSvtUB5grC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing stance classification:\n",
      "======================================================================\n",
      "Original Comment: The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\n",
      "======================================================================\n",
      "\n",
      "Reply 1: The newer ones fail to live up to the sophistry of the older movies from the 70's.\n",
      "Stance: agree\n",
      "--------------------------------------------------\n",
      "Reply 2: Frank Herbert wrote a lot of books.\n",
      "Stance: neutral\n",
      "--------------------------------------------------\n",
      "Reply 3: I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\n",
      "Stance: disagree\n",
      "--------------------------------------------------\n",
      "Reply 4: The quick red fox jumped over the lazy brown dog.\n",
      "Stance: neutral\n",
      "--------------------------------------------------\n",
      "Reply 5: Yeah, this new movie is a real masterpiece, lol!!\n",
      "Stance: disagree\n",
      "--------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "SUMMARY OF RESULTS:\n",
      "======================================================================\n",
      "1. [AGREE] The newer ones fail to live up to the so...\n",
      "2. [NEUTRAL] Frank Herbert wrote a lot of books.\n",
      "3. [DISAGREE] I think the new Dune movie better captur...\n",
      "4. [NEUTRAL] The quick red fox jumped over the lazy b...\n",
      "5. [DISAGREE] Yeah, this new movie is a real masterpie...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the test comment and multiple replies\n",
    "test_comment = \"The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\"\n",
    "\n",
    "test_replies = [\n",
    "    \"The newer ones fail to live up to the sophistry of the older movies from the 70's.\",\n",
    "    \"Frank Herbert wrote a lot of books.\",\n",
    "    \"I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\",\n",
    "    \"The quick red fox jumped over the lazy brown dog.\",\n",
    "    \"Yeah, this new movie is a real masterpiece, lol!!\"\n",
    "]\n",
    "\n",
    "print(\"Testing stance classification:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Original Comment: {test_comment}\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Run stance classification for each reply\n",
    "results = []\n",
    "\n",
    "for i, reply in enumerate(test_replies, 1):\n",
    "    print(f\"Reply {i}: {reply}\")\n",
    "    \n",
    "    # Use the stance_chain to get classification\n",
    "    result = stance_chain.invoke({\n",
    "        \"comment\": test_comment,\n",
    "        \"reply\": reply\n",
    "    })\n",
    "    \n",
    "    # Store result and display\n",
    "    results.append(result.strip())  # Remove any extra whitespace\n",
    "    print(f\"Stance: {result.strip()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY OF RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, (reply, stance) in enumerate(zip(test_replies, results), 1):\n",
    "    # Truncate long replies for summary\n",
    "    short_reply = reply[:40] + \"...\" if len(reply) > 40 else reply\n",
    "    print(f\"{i}. [{stance.upper()}] {short_reply}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ljgw93Vr5grD"
   },
   "source": [
    "# Few-shot Prompt\n",
    "\n",
    "Now, Please create a LangChain FewShotPromptTemplate for classifying the stance of a reply to a comment. Use the following template for each example and create an example prompt using example_prompt for the examples in the few-shot prompt template:\n",
    "\n",
    "comment: [comment]\n",
    "reply: [reply]\n",
    "stance: [stance]\n",
    "\n",
    "Then, use the following structure for the few-shot prompt:\n",
    "prefix = '''Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\", \"disagree\", or \"neutral\" toward the comment.'''\n",
    "\n",
    "suffix = '''Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:'''\n",
    "\n",
    "Create five few-shot examples with different comments and replies, including at least one for each possible stance: \"agree\", \"disagree\", and \"neutral\". Provide the code that constructs the FewShotPromptTemplate using the examples and the given prefix and suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mLuNW7HJ5grD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Prompt Template Created!\n",
      "======================================================================\n",
      "Formatted Few-Shot Prompt:\n",
      "======================================================================\n",
      "Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\", \"disagree\", or \"neutral\" toward the comment.\n",
      "\n",
      "comment: I think the new policy will help improve efficiency.\n",
      "reply: I agree, it will definitely streamline our operations.\n",
      "stance: agree\n",
      "\n",
      "comment: The new education reform seems promising.\n",
      "reply: I disagree, it doesn't address the underlying issues.\n",
      "stance: disagree\n",
      "\n",
      "comment: The park renovation project is a good idea.\n",
      "reply: I'm not sure. The location might be an issue.\n",
      "stance: neutral\n",
      "\n",
      "comment: Artificial intelligence will revolutionize healthcare.\n",
      "reply: Absolutely, it has the potential to save many lives.\n",
      "stance: agree\n",
      "\n",
      "comment: The economy is showing signs of recovery after the pandemic.\n",
      "reply: I disagree, the recovery seems slow and uneven across sectors.\n",
      "stance: disagree\n",
      "\n",
      "Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
      "comment: The new delivery route optimization will save us fuel costs.\n",
      "reply: I'm not convinced it will make much difference.\n",
      "stance:\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# Define the template for each individual example\n",
    "example_template = '''comment: {comment}\n",
    "reply: {reply}\n",
    "stance: {stance}'''\n",
    "\n",
    "# Create the example prompt template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\", \"stance\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Create five diverse few-shot examples covering all stances\n",
    "examples = [\n",
    "    {\n",
    "        'comment': \"I think the new policy will help improve efficiency.\",\n",
    "        'reply': \"I agree, it will definitely streamline our operations.\",\n",
    "        'stance': 'agree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The new education reform seems promising.\", \n",
    "        'reply': \"I disagree, it doesn't address the underlying issues.\",\n",
    "        'stance': 'disagree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The park renovation project is a good idea.\",\n",
    "        'reply': \"I'm not sure. The location might be an issue.\",\n",
    "        'stance': 'neutral'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"Artificial intelligence will revolutionize healthcare.\",\n",
    "        'reply': \"Absolutely, it has the potential to save many lives.\",\n",
    "        'stance': 'agree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The economy is showing signs of recovery after the pandemic.\",\n",
    "        'reply': \"I disagree, the recovery seems slow and uneven across sectors.\",\n",
    "        'stance': 'disagree'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prefix and suffix as provided\n",
    "prefix = '''Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\", \"disagree\", or \"neutral\" toward the comment.'''\n",
    "\n",
    "suffix = '''Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:'''\n",
    "\n",
    "# Create the FewShotPromptTemplate\n",
    "few_shot_stance_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"comment\", \"reply\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Test the few-shot prompt\n",
    "print(\"Few-Shot Prompt Template Created!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage - format the template with new data\n",
    "test_comment = \"The new delivery route optimization will save us fuel costs.\"\n",
    "test_reply = \"I'm not convinced it will make much difference.\"\n",
    "\n",
    "formatted_few_shot_prompt = few_shot_stance_prompt.format(\n",
    "    comment=test_comment,\n",
    "    reply=test_reply\n",
    ")\n",
    "\n",
    "print(\"Formatted Few-Shot Prompt:\")\n",
    "print(\"=\" * 70)\n",
    "print(formatted_few_shot_prompt)\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Prompt Template Created!\n",
      "======================================================================\n",
      "Few-Shot Chain Created!\n",
      "Testing few-shot vs regular prompt...\n",
      "======================================================================\n",
      "COMPARISON TEST:\n",
      "Comment: The new delivery route optimization will save us fuel costs.\n",
      "Reply: I'm not convinced it will make much difference.\n",
      "\n",
      "Regular prompt result:\n",
      "Stance: neutral\n",
      "\n",
      "Few-shot prompt result:\n",
      "Stance: neutral\n",
      "======================================================================\n",
      "Formatted Few-Shot Prompt:\n",
      "======================================================================\n",
      "Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\", \"disagree\", or \"neutral\" toward the comment.\n",
      "\n",
      "comment: I think the new policy will help improve efficiency.\n",
      "reply: I agree, it will definitely streamline our operations.\n",
      "stance: agree\n",
      "\n",
      "comment: The new education reform seems promising.\n",
      "reply: I disagree, it doesn't address the underlying issues.\n",
      "stance: disagree\n",
      "\n",
      "comment: The park renovation project is a good idea.\n",
      "reply: I'm not sure. The location might be an issue.\n",
      "stance: neutral\n",
      "\n",
      "comment: Artificial intelligence will revolutionize healthcare.\n",
      "reply: Absolutely, it has the potential to save many lives.\n",
      "stance: agree\n",
      "\n",
      "comment: The economy is showing signs of recovery after the pandemic.\n",
      "reply: I disagree, the recovery seems slow and uneven across sectors.\n",
      "stance: disagree\n",
      "\n",
      "Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
      "comment: The new delivery route optimization will save us fuel costs.\n",
      "reply: I'm not convinced it will make much difference.\n",
      "stance:\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# Define the template for each individual example\n",
    "example_template = '''comment: {comment}\n",
    "reply: {reply}\n",
    "stance: {stance}'''\n",
    "\n",
    "# Create the example prompt template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\", \"stance\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Create five diverse few-shot examples covering all stances\n",
    "examples = [\n",
    "    {\n",
    "        'comment': \"I think the new policy will help improve efficiency.\",\n",
    "        'reply': \"I agree, it will definitely streamline our operations.\",\n",
    "        'stance': 'agree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The new education reform seems promising.\", \n",
    "        'reply': \"I disagree, it doesn't address the underlying issues.\",\n",
    "        'stance': 'disagree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The park renovation project is a good idea.\",\n",
    "        'reply': \"I'm not sure. The location might be an issue.\",\n",
    "        'stance': 'neutral'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"Artificial intelligence will revolutionize healthcare.\",\n",
    "        'reply': \"Absolutely, it has the potential to save many lives.\",\n",
    "        'stance': 'agree'\n",
    "    },\n",
    "    {\n",
    "        'comment': \"The economy is showing signs of recovery after the pandemic.\",\n",
    "        'reply': \"I disagree, the recovery seems slow and uneven across sectors.\",\n",
    "        'stance': 'disagree'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prefix and suffix as provided\n",
    "prefix = '''Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\", \"disagree\", or \"neutral\" toward the comment.'''\n",
    "\n",
    "suffix = '''Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:'''\n",
    "\n",
    "# Create the FewShotPromptTemplate\n",
    "few_shot_stance_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"comment\", \"reply\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Test the few-shot prompt\n",
    "print(\"Few-Shot Prompt Template Created!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define a mock LLM for demonstration (replace with a real LLM as needed)\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "\n",
    "# This mock LLM will always return \"neutral\" for demonstration\n",
    "llm = FakeListLLM(responses=[\"neutral\"])\n",
    "\n",
    "# Create a new chain using the few-shot prompt template\n",
    "few_shot_stance_chain = few_shot_stance_prompt | llm\n",
    "\n",
    "print(\"Few-Shot Chain Created!\")\n",
    "print(\"Testing few-shot vs regular prompt...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compare regular vs few-shot on the same example\n",
    "test_comment = \"The new delivery route optimization will save us fuel costs.\"\n",
    "test_reply = \"I'm not convinced it will make much difference.\"\n",
    "\n",
    "print(\"COMPARISON TEST:\")\n",
    "print(f\"Comment: {test_comment}\")\n",
    "print(f\"Reply: {test_reply}\")\n",
    "print()\n",
    "\n",
    "# Create a regular prompt template for comparison\n",
    "regular_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\"],\n",
    "    template='''Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:'''\n",
    ")\n",
    "\n",
    "# Create a regular stance_chain using the regular prompt and llm\n",
    "regular_stance_chain = regular_prompt | llm\n",
    "\n",
    "# Test regular stance_chain\n",
    "print(\"Regular prompt result:\")\n",
    "regular_result = regular_stance_chain.invoke({\n",
    "    \"comment\": test_comment,\n",
    "    \"reply\": test_reply\n",
    "})\n",
    "print(f\"Stance: {regular_result.strip()}\")\n",
    "print()\n",
    "\n",
    "# Test few-shot chain\n",
    "print(\"Few-shot prompt result:\")\n",
    "few_shot_result = few_shot_stance_chain.invoke({\n",
    "    \"comment\": test_comment,\n",
    "    \"reply\": test_reply  \n",
    "})\n",
    "print(f\"Stance: {few_shot_result.strip()}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example usage - format the template with new data\n",
    "test_comment = \"The new delivery route optimization will save us fuel costs.\"\n",
    "test_reply = \"I'm not convinced it will make much difference.\"\n",
    "\n",
    "formatted_few_shot_prompt = few_shot_stance_prompt.format(\n",
    "    comment=test_comment,\n",
    "    reply=test_reply\n",
    ")\n",
    "\n",
    "print(\"Formatted Few-Shot Prompt:\")\n",
    "print(\"=\" * 70)\n",
    "print(formatted_few_shot_prompt)\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompt\n",
    "\n",
    "Please generate code that uses chain-of-thought (CoT) prompting to classify the stance of a reply to a comment. The process should consist of two stages:\n",
    "\n",
    "1. First Stage (Explanatory Step):\n",
    "- Generate an explanation for the stance (agree, disagree, neutral) of the reply toward the comment.\n",
    "- Use a prompt template for this step with the variables \"comment\" and \"reply\".\n",
    "- Output: \"stance_reason\".\n",
    "\n",
    "2. Second Stage (Final Classification Step):\n",
    "- Based on the explanation from the first stage (\"stance_reason\"), determine the final stance of the reply.\n",
    "- Use a second prompt template for this step with the variables \"comment\", \"reply\", and \"stance_reason\".\n",
    "- Output: The final stance as \"agree\", \"disagree\", or \"neutral\".\n",
    "\n",
    "Use the \"RunnablePassthrough\" to pass the \"comment\" and \"reply\" variables from the first chain to the second chain, and chain the steps together using the \"|\" operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Implementing Chain-of-Thought (CoT) Stance Classification\n",
      "======================================================================\n",
      "✅ Stage 1 Prompt Template Created (Explanatory Step)\n",
      "✅ Stage 2 Prompt Template Created (Final Classification)\n",
      "✅ Chain-of-Thought Stance Classification Chain Created!\n",
      "🔗 Chain Structure: Input → Reasoning → Classification → Output\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-Thought Prompt Implementation\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"🧠 Implementing Chain-of-Thought (CoT) Stance Classification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Stage 1: Explanatory Step - Generate reasoning for the stance\n",
    "reasoning_template = \"\"\"Analyze the relationship between the following comment and reply. \n",
    "Provide a detailed explanation of why the reply would be classified as \"agree\", \"disagree\", or \"neutral\" toward the comment.\n",
    "Focus on the key indicators in the reply that show the stance.\n",
    "\n",
    "Comment: {comment}\n",
    "Reply: {reply}\n",
    "\n",
    "Explanation of stance reasoning:\"\"\"\n",
    "\n",
    "reasoning_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\"],\n",
    "    template=reasoning_template\n",
    ")\n",
    "\n",
    "print(\"✅ Stage 1 Prompt Template Created (Explanatory Step)\")\n",
    "\n",
    "# Stage 2: Final Classification Step - Use reasoning to determine final stance\n",
    "classification_template = \"\"\"Based on the explanation provided, classify the stance of the reply toward the comment.\n",
    "\n",
    "Comment: {comment}\n",
    "Reply: {reply}\n",
    "Reasoning: {stance_reason}\n",
    "\n",
    "Based on this reasoning, the stance of the reply toward the comment is (respond with only one word - \"agree\", \"disagree\", or \"neutral\"):\"\"\"\n",
    "\n",
    "classification_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\", \"reply\", \"stance_reason\"],\n",
    "    template=classification_template\n",
    ")\n",
    "\n",
    "print(\"✅ Stage 2 Prompt Template Created (Final Classification)\")\n",
    "\n",
    "# Create the Chain-of-Thought chain using RunnablePassthrough\n",
    "# This creates a two-stage pipeline where:\n",
    "# 1. First stage generates reasoning\n",
    "# 2. Second stage uses that reasoning to make final classification\n",
    "\n",
    "cot_stance_chain = (\n",
    "    {\n",
    "        \"comment\": RunnablePassthrough(),\n",
    "        \"reply\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnablePassthrough.assign(\n",
    "        stance_reason=reasoning_prompt | llm | StrOutputParser()\n",
    "    )\n",
    "    | classification_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ Chain-of-Thought Stance Classification Chain Created!\")\n",
    "print(\"🔗 Chain Structure: Input → Reasoning → Classification → Output\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing Chain-of-Thought Stance Classification\n",
      "======================================================================\n",
      "📝 Test Case:\n",
      "Comment: The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\n",
      "Reply: I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\n",
      "\n",
      "🔍 Chain-of-Thought Processing...\n",
      "--------------------------------------------------\n",
      "🎯 Final Classification: agree\n",
      "======================================================================\n",
      "\n",
      "🔄 Comparison: CoT vs Regular Classification\n",
      "======================================================================\n",
      "\n",
      "📊 Test Case 1:\n",
      "Comment: The new policy will improve workplace efficiency.\n",
      "Reply: I agree completely, it addresses our main concerns.\n",
      "🧠 CoT Result: agree\n",
      "⚡ Regular Result: agree\n",
      "🎯 Expected: agree\n",
      "----------------------------------------\n",
      "\n",
      "📊 Test Case 2:\n",
      "Comment: Remote work is the future of employment.\n",
      "Reply: I disagree, in-person collaboration is still essential.\n",
      "🧠 CoT Result: disagree\n",
      "⚡ Regular Result: disagree\n",
      "🎯 Expected: disagree\n",
      "----------------------------------------\n",
      "\n",
      "📊 Test Case 3:\n",
      "Comment: The weather has been quite unpredictable this month.\n",
      "Reply: That's an interesting observation about climate patterns.\n",
      "🧠 CoT Result: neutral\n",
      "⚡ Regular Result: neutral\n",
      "🎯 Expected: neutral\n",
      "----------------------------------------\n",
      "\n",
      "✅ Chain-of-Thought testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test the Chain-of-Thought Stance Classification\n",
    "print(\"🧪 Testing Chain-of-Thought Stance Classification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test with the original Dune movie example\n",
    "test_comment = \"The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\"\n",
    "test_reply = \"I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\"\n",
    "\n",
    "print(\"📝 Test Case:\")\n",
    "print(f\"Comment: {test_comment}\")\n",
    "print(f\"Reply: {test_reply}\")\n",
    "print()\n",
    "print(\"🔍 Chain-of-Thought Processing...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Invoke the CoT chain\n",
    "result = cot_stance_chain.invoke({\n",
    "    \"comment\": test_comment,\n",
    "    \"reply\": test_reply\n",
    "})\n",
    "\n",
    "print(f\"🎯 Final Classification: {result.strip()}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test with multiple examples to compare CoT vs regular classification\n",
    "print(\"\\n🔄 Comparison: CoT vs Regular Classification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"comment\": \"The new policy will improve workplace efficiency.\",\n",
    "        \"reply\": \"I agree completely, it addresses our main concerns.\",\n",
    "        \"expected\": \"agree\"\n",
    "    },\n",
    "    {\n",
    "        \"comment\": \"Remote work is the future of employment.\",\n",
    "        \"reply\": \"I disagree, in-person collaboration is still essential.\",\n",
    "        \"expected\": \"disagree\"\n",
    "    },\n",
    "    {\n",
    "        \"comment\": \"The weather has been quite unpredictable this month.\",\n",
    "        \"reply\": \"That's an interesting observation about climate patterns.\",\n",
    "        \"expected\": \"neutral\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n📊 Test Case {i}:\")\n",
    "    print(f\"Comment: {case['comment']}\")\n",
    "    print(f\"Reply: {case['reply']}\")\n",
    "    \n",
    "    # CoT classification\n",
    "    cot_result = cot_stance_chain.invoke({\n",
    "        \"comment\": case[\"comment\"],\n",
    "        \"reply\": case[\"reply\"]\n",
    "    })\n",
    "    \n",
    "    # Regular classification for comparison\n",
    "    regular_result = stance_chain.invoke({\n",
    "        \"comment\": case[\"comment\"],\n",
    "        \"reply\": case[\"reply\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"🧠 CoT Result: {cot_result.strip()}\")\n",
    "    print(f\"⚡ Regular Result: {regular_result.strip()}\")\n",
    "    print(f\"🎯 Expected: {case['expected']}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n✅ Chain-of-Thought testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "### 🧠 How CoT Works\n",
    "\n",
    "Chain-of-Thought prompting is a technique that breaks down complex reasoning tasks into explicit intermediate steps. Instead of asking the model to directly classify the stance, we:\n",
    "\n",
    "1. **Stage 1 (Reasoning)**: Ask the model to explain WHY a reply has a particular stance toward a comment\n",
    "2. **Stage 2 (Classification)**: Use that reasoning to make the final classification\n",
    "\n",
    "### 🎯 Benefits of CoT Prompting\n",
    "\n",
    "- **Improved Accuracy**: By forcing explicit reasoning, models often make better decisions\n",
    "- **Transparency**: We can see the model's reasoning process\n",
    "- **Consistency**: The two-stage process reduces random classification errors\n",
    "- **Debugging**: If classification is wrong, we can examine the reasoning step\n",
    "\n",
    "### 🔗 Technical Implementation\n",
    "\n",
    "Our CoT chain uses `RunnablePassthrough` to:\n",
    "- Pass the original `comment` and `reply` through both stages\n",
    "- Generate `stance_reason` in stage 1\n",
    "- Use all three variables (`comment`, `reply`, `stance_reason`) in stage 2\n",
    "\n",
    "### 📊 Expected Improvements\n",
    "\n",
    "CoT prompting typically shows improvements in:\n",
    "- **Complex cases** where the stance isn't immediately obvious\n",
    "- **Ambiguous replies** that could be interpreted multiple ways\n",
    "- **Consistency** across similar examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Examining the Chain-of-Thought Reasoning Process\n",
      "======================================================================\n",
      "📝 Test Input:\n",
      "Comment: The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\n",
      "Reply: I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\n",
      "\n",
      "🧠 Stage 1: Generating Reasoning...\n",
      "--------------------------------------------------\n",
      "💭 Model's Reasoning:\n",
      "The reply agrees with the comment by stating that while the movie may not perfectly capture the content, it still manages to convey the philosophy of Frank Herbert's work. The phrase \"if not the content\" suggests that the movie captures the spirit of the original material.\n",
      "\n",
      "⚖️ Stage 2: Final Classification...\n",
      "--------------------------------------------------\n",
      "🎯 Final Classification:\n",
      "<|assistant|>\n",
      "agree\n",
      "\n",
      "✅ This demonstrates how CoT provides:\n",
      "  • Transparent reasoning process\n",
      "  • Explicit justification for decisions\n",
      "  • Ability to debug classification errors\n",
      "  • More consistent and reliable results\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the reasoning step explicitly\n",
    "print(\"🔍 Examining the Chain-of-Thought Reasoning Process\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Let's manually run each stage to see the reasoning\n",
    "test_comment = \"The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\"\n",
    "test_reply = \"I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\"\n",
    "\n",
    "print(\"📝 Test Input:\")\n",
    "print(f\"Comment: {test_comment}\")\n",
    "print(f\"Reply: {test_reply}\")\n",
    "print()\n",
    "\n",
    "# Stage 1: Generate reasoning\n",
    "print(\"🧠 Stage 1: Generating Reasoning...\")\n",
    "print(\"-\" * 50)\n",
    "reasoning_result = reasoning_prompt.format(comment=test_comment, reply=test_reply)\n",
    "stance_reason = llm.invoke(reasoning_result)\n",
    "\n",
    "print(\"💭 Model's Reasoning:\")\n",
    "print(stance_reason.strip())\n",
    "print()\n",
    "\n",
    "# Stage 2: Use reasoning for classification\n",
    "print(\"⚖️ Stage 2: Final Classification...\")\n",
    "print(\"-\" * 50)\n",
    "classification_input = classification_prompt.format(\n",
    "    comment=test_comment, \n",
    "    reply=test_reply, \n",
    "    stance_reason=stance_reason.strip()\n",
    ")\n",
    "final_classification = llm.invoke(classification_input)\n",
    "\n",
    "print(\"🎯 Final Classification:\")\n",
    "print(final_classification.strip())\n",
    "print()\n",
    "\n",
    "print(\"✅ This demonstrates how CoT provides:\")\n",
    "print(\"  • Transparent reasoning process\")\n",
    "print(\"  • Explicit justification for decisions\")\n",
    "print(\"  • Ability to debug classification errors\")\n",
    "print(\"  • More consistent and reliable results\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Analyzing Test Case 2 Classification Issue\n",
      "======================================================================\n",
      "📝 Test Case 2 Details:\n",
      "Comment: Remote work is the future of employment.\n",
      "Reply: I disagree, in-person collaboration is still essential.\n",
      "\n",
      "🧠 Running Chain-of-Thought Analysis...\n",
      "--------------------------------------------------\n",
      "💭 Stage 1 - Model's Reasoning:\n",
      "<|assistant|>\n",
      "The reply is classified as \"disagree\" because the statement directly contradicts the comment, which asserts that remote work is the future of employment. The word \"disagree\" explicitly indicates a negative stance, suggesting that the speaker believes in-person collaboration remains crucial. The use of the word \"essential\" further emphasizes this disagreement by highlighting the importance of in-person collaboration, which is seen as a necessary component of employment in this context.\n",
      "\n",
      "⚖️ Stage 2 - Final Classification:\n",
      "Result: <|assistant|>\n",
      "disagree\n",
      "\n",
      "🔄 Comparison:\n",
      "CoT Result: <|assistant|>\n",
      "disagree\n",
      "Regular Result: disagree\n",
      "\n",
      "📊 Analysis:\n",
      "• The reply explicitly states 'I disagree'\n",
      "• This is a clear linguistic signal for disagreement\n",
      "• Both methods should classify this as 'disagree'\n",
      "• If you saw 'neutral', it might be due to:\n",
      "  - Model variability (different runs can give different results)\n",
      "  - Previous test with different examples\n",
      "  - Looking at a different test case\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Detailed Analysis of Test Case 2 - \"I disagree\" Classification\n",
    "print(\"🔍 Analyzing Test Case 2 Classification Issue\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Let's examine Test Case 2 specifically\n",
    "case2_comment = \"Remote work is the future of employment.\"\n",
    "case2_reply = \"I disagree, in-person collaboration is still essential.\"\n",
    "\n",
    "print(\"📝 Test Case 2 Details:\")\n",
    "print(f\"Comment: {case2_comment}\")\n",
    "print(f\"Reply: {case2_reply}\")\n",
    "print()\n",
    "\n",
    "print(\"🧠 Running Chain-of-Thought Analysis...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Stage 1: Get the reasoning\n",
    "reasoning_input = reasoning_prompt.format(comment=case2_comment, reply=case2_reply)\n",
    "reasoning_output = llm.invoke(reasoning_input)\n",
    "\n",
    "print(\"💭 Stage 1 - Model's Reasoning:\")\n",
    "print(reasoning_output.strip())\n",
    "print()\n",
    "\n",
    "# Stage 2: Get final classification\n",
    "classification_input = classification_prompt.format(\n",
    "    comment=case2_comment, \n",
    "    reply=case2_reply, \n",
    "    stance_reason=reasoning_output.strip()\n",
    ")\n",
    "final_classification = llm.invoke(classification_input)\n",
    "\n",
    "print(\"⚖️ Stage 2 - Final Classification:\")\n",
    "print(f\"Result: {final_classification.strip()}\")\n",
    "print()\n",
    "\n",
    "# Also test the regular chain for comparison\n",
    "regular_result = stance_chain.invoke({\n",
    "    \"comment\": case2_comment,\n",
    "    \"reply\": case2_reply\n",
    "})\n",
    "\n",
    "print(\"🔄 Comparison:\")\n",
    "print(f\"CoT Result: {final_classification.strip()}\")\n",
    "print(f\"Regular Result: {regular_result.strip()}\")\n",
    "print()\n",
    "\n",
    "print(\"📊 Analysis:\")\n",
    "print(\"• The reply explicitly states 'I disagree'\")\n",
    "print(\"• This is a clear linguistic signal for disagreement\")\n",
    "print(\"• Both methods should classify this as 'disagree'\")\n",
    "print(\"• If you saw 'neutral', it might be due to:\")\n",
    "print(\"  - Model variability (different runs can give different results)\")\n",
    "print(\"  - Previous test with different examples\")\n",
    "print(\"  - Looking at a different test case\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agentic_ai_env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
